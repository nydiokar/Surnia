{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ca78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6394fa60",
   "metadata": {},
   "source": [
    "# Wallet Agent Analysis Notebook\n",
    "\n",
    "This notebook loads real wallet data, builds a prompt for an LLM (OpenAI GPT-4), and displays the analysis.\n",
    "\n",
    "**Dependencies:**\n",
    "- requests\n",
    "- openai\n",
    "- pydantic\n",
    "- jupyter\n",
    "\n",
    "You can install them with:\n",
    "```python\n",
    "!pip install openai requests pydantic\n",
    "```\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Code**\n",
    "```python\n",
    "# Install dependencies if needed\n",
    "# Uncomment the next line if running for the first time\n",
    "# !pip install openai requests pydantic\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Markdown**\n",
    "```markdown\n",
    "## Set your OpenAI API key securely\n",
    "You can use an environment variable or input() for security.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Code**\n",
    "```python\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Option 1: Set via environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Option 2: Prompt for key (uncomment if needed)\n",
    "# openai.api_key = input('Enter your OpenAI API key: ')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Markdown**\n",
    "```markdown\n",
    "## Load agent input data\n",
    "This should be generated by fetch_wallet_data.py for a real wallet.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Code**\n",
    "```python\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = Path('../agent_input.json') if not Path('agent_input.json').exists() else Path('agent_input.json')\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError('agent_input.json not found. Please run fetch_wallet_data.py first.')\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    agent_input = json.load(f)\n",
    "\n",
    "# Show the loaded data\n",
    "import pprint\n",
    "pprint.pprint(agent_input)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Markdown**\n",
    "```markdown\n",
    "## Edit the instruction (if needed)\n",
    "You can change the instruction for the LLM here.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Code**\n",
    "```python\n",
    "# Edit the instruction\n",
    "agent_input['instruction'] = \"Provide a comprehensive summary of this wallet's trading activity, performance, and any notable behavioral or risk patterns.\"\n",
    "print('Instruction set to:', agent_input['instruction'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Markdown**\n",
    "```markdown\n",
    "## Build the LLM prompt\n",
    "This cell formats the agent input for the LLM.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Code**\n",
    "```python\n",
    "def build_prompt(agent_input):\n",
    "    prompt = (\n",
    "        f\"Wallet Analysis Request:\\n\"\n",
    "        f\"Instruction: {agent_input['instruction']}\\n\"\n",
    "        f\"Summary: {json.dumps(agent_input['summary'], indent=2)}\\n\"\n",
    "        f\"PNL Overview: {json.dumps(agent_input['pnl_overview'], indent=2)}\\n\"\n",
    "        f\"Behavior: {json.dumps(agent_input['behavior'], indent=2)}\\n\"\n",
    "        f\"Token Performance: {json.dumps(agent_input['token_performance'], indent=2)}\\n\"\n",
    "    )\n",
    "    if agent_input.get('similarity'):\n",
    "        prompt += f\"Similarity: {json.dumps(agent_input['similarity'], indent=2)}\\n\"\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(agent_input)\n",
    "print(prompt[:1000] + ('...\\n' if len(prompt) > 1000 else ''))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 11. **Markdown**\n",
    "```markdown\n",
    "## Call OpenAI and display the result\n",
    "This cell sends the prompt to GPT-4 and prints the response.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 12. **Code**\n",
    "```python\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a crypto wallet analysis expert.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 13. **Markdown**\n",
    "```markdown\n",
    "## Next steps and extension ideas\n",
    "- Try different instructions and prompt formats.\n",
    "- Add structured output parsing (e.g., ask LLM to return JSON).\n",
    "- Analyze each section separately and then synthesize.\n",
    "- Integrate with your dashboard or API.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**How to use:**  \n",
    "- In VSCode or Jupyter, click “+ Code” or “+ Markdown” to add a new cell of the correct type.\n",
    "- Paste the content above into each cell, in order.\n",
    "\n",
    "Let me know if you want the full .ipynb JSON for direct import!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf917b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\solastic\\prj\\surnia\\myenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/765.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 765.0/765.0 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 11.5 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, sniffio, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.7.14 charset_normalizer-3.4.2 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.97.0 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed\n",
    "# Uncomment the next line if running for the first time\n",
    "%pip install openai requests pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052943b",
   "metadata": {},
   "source": [
    "## Set your OpenAI API key securely\n",
    "You can use an environment variable or input() for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb25426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Option 1: Set via environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Option 2: Prompt for key (uncomment if needed)\n",
    "# openai.api_key = input('Enter your OpenAI API key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2382a",
   "metadata": {},
   "source": [
    "## Load agent input data\n",
    "This should be generated by fetch_wallet_data.py for a real wallet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90985de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "agent_input.json not found. Please run fetch_wallet_data.py first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m input_path = Path(\u001b[33m'\u001b[39m\u001b[33m../agent_input.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(\u001b[33m'\u001b[39m\u001b[33magent_input.json\u001b[39m\u001b[33m'\u001b[39m).exists() \u001b[38;5;28;01melse\u001b[39;00m Path(\u001b[33m'\u001b[39m\u001b[33magent_input.json\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_path.exists():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33magent_input.json not found. Please run fetch_wallet_data.py first.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      9\u001b[39m     agent_input = json.load(f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: agent_input.json not found. Please run fetch_wallet_data.py first."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = Path('../agent_input.json') if not Path('agent_input.json').exists() else Path('agent_input.json')\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError('agent_input.json not found. Please run fetch_wallet_data.py first.')\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    agent_input = json.load(f)\n",
    "\n",
    "# Show the loaded data\n",
    "import pprint\n",
    "pprint.pprint(agent_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d6859",
   "metadata": {},
   "source": [
    "## Edit the instruction (if needed)\n",
    "You can change the instruction for the LLM here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the instruction\n",
    "agent_input['instruction'] = \"Provide a comprehensive summary of this wallet's trading activity, performance, and any notable behavioral or risk patterns.\"\n",
    "print('Instruction set to:', agent_input['instruction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb080e60",
   "metadata": {},
   "source": [
    "## Build the LLM prompt\n",
    "This cell formats the agent input for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fedf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(agent_input):\n",
    "    prompt = (\n",
    "        f\"Wallet Analysis Request:\\n\"\n",
    "        f\"Instruction: {agent_input['instruction']}\\n\"\n",
    "        f\"Summary: {json.dumps(agent_input['summary'], indent=2)}\\n\"\n",
    "        f\"PNL Overview: {json.dumps(agent_input['pnl_overview'], indent=2)}\\n\"\n",
    "        f\"Behavior: {json.dumps(agent_input['behavior'], indent=2)}\\n\"\n",
    "        f\"Token Performance: {json.dumps(agent_input['token_performance'], indent=2)}\\n\"\n",
    "    )\n",
    "    if agent_input.get('similarity'):\n",
    "        prompt += f\"Similarity: {json.dumps(agent_input['similarity'], indent=2)}\\n\"\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(agent_input)\n",
    "print(prompt[:1000] + ('...\\n' if len(prompt) > 1000 else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599ed380",
   "metadata": {},
   "source": [
    "## Call OpenAI and display the result\n",
    "This cell sends the prompt to GPT-4 and prints the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f273662",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a crypto wallet analysis expert.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17520e09",
   "metadata": {},
   "source": [
    "## Next steps and extension ideas\n",
    "- Try different instructions and prompt formats.\n",
    "- Add structured output parsing (e.g., ask LLM to return JSON).\n",
    "- Analyze each section separately and then synthesize.\n",
    "- Integrate with your dashboard or API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
